name: Container Dispatcher

on:
  push:
    paths:
      - 'docker/**'

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      changed-containers: ${{ steps.extract-folders.outputs.containers }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Get changed files
        id: get-changes
        uses: tj-actions/changed-files@v44
        with:
          files: |
            docker/**

      - name: Extract top-level container folders
        id: extract-folders
        run: |
          # Get unique first-level folders under /docker
          FOLDERS=$(echo "${{ steps.get-changes.outputs.all_changed_files }}" \
            | tr ' ' '\n' \
            | awk -F'/' '{print $2}' \
            | sort -u)

          # build JSON array from newline-separated folders
          if [ -z "$FOLDERS" ]; then
            JSON_ARRAY="[]"
          else
            JSON_ARRAY=$(echo "$FOLDERS" | python3 -c 'import sys,json; print(json.dumps([l for l in sys.stdin.read().split() if l]))')
          fi

          echo "Changed container folders: $JSON_ARRAY"
          echo "containers=$JSON_ARRAY" >> $GITHUB_OUTPUT

  read-config:
    needs: detect-changes
    runs-on: ubuntu-latest
    outputs:
      containers: ${{ steps.build.outputs.containers }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Ensure `yq` is available
        run: |
          if ! command -v yq >/dev/null 2>&1; then
            echo "Installing yq"
            echo "${{ secrets.SUDO }}" | sudo -S apt-get update
            echo "${{ secrets.SUDO }}" | sudo -S apt-get install -y yq
          fi

      - name: Build container config array
        id: build
        run: |
          CONTAINERS_JSON='${{ needs.detect-changes.outputs.containers }}'

          # produce newline-separated list
          CONTAINERS=$(python3 -c "import json,sys; arr=json.loads(sys.argv[1]) if len(sys.argv)>1 else []; print('\n'.join(arr))" "$CONTAINERS_JSON")

          # for each container read configuration.yml and emit JSON object per-line
          TMPFILE=$(mktemp)
          > $TMPFILE
          while read -r C; do
            CONFIG_PATH="docker/$C/configuration.yml"
            if [ -f "$CONFIG_PATH" ]; then
              NAME=$(yq -r '.name' "$CONFIG_PATH")
              FQDN=$(yq -r '.fqdn' "$CONFIG_PATH")
              CERT=$(yq -r '.certificate' "$CONFIG_PATH")
              EXTERNAL=$(yq -r '.external_access' "$CONFIG_PATH")
              DEDICATED_IP=$(yq -r '.dedicated_ip' "$CONFIG_PATH")
              CONTAINER_ENVIRONMENT=$(yq -r '.container_environment' "$CONFIG_PATH")
              CONTAINER_HOST=$(yq -r '.container_host' "$CONFIG_PATH")
              printf '%s\n' "{\"container_folder\":\"$C\",\"name\":\"$NAME\",\"fqdn\":\"$FQDN\",\"certificate\":\"$CERT\",\"external_access\":\"$EXTERNAL\",\"dedicated_ip\":\"$DEDICATED_IP\",\"container_environment\":\"$CONTAINER_ENVIRONMENT\",\"container_host\":\"$CONTAINER_HOST\"}" >> $TMPFILE
            fi
          done <<< "$CONTAINERS"

          # aggregate to JSON array
          CONTAINERS_JSON=$(python3 -c "import json,sys; objs=[json.loads(l) for l in sys.stdin.read().splitlines() if l.strip()]; print(json.dumps(objs))" < $TMPFILE)

          echo "containers=$CONTAINERS_JSON" >> $GITHUB_OUTPUT

      - name: Process changed containers sequentially
        run: |
          set -euo pipefail
          CONTAINERS_JSON='${{ steps.build.outputs.containers }}'

          # print tab-separated fields per container: name, fqdn, certificate, dedicated_ip, env, host, folder
          python3 -c "import json,sys; arr=json.loads(sys.argv[1]) if len(sys.argv)>1 else []; print('\n'.join(['\t'.join([o.get('name',''), o.get('fqdn',''), o.get('certificate',''), o.get('dedicated_ip',''), o.get('container_environment',''), o.get('container_host',''), o.get('container_folder','')]) for o in arr]))" "$CONTAINERS_JSON" | while IFS=$'\t' read -r NAME FQDN CERT DEDIP ENV HOST FOLDER; do

            echo "Processing container: $NAME (folder: $FOLDER)"

            # Create cert if requested
            if [ "$CERT" = "true" ]; then
              echo "Ensuring Ansible installed for cert step"
              if ! command -v ansible >/dev/null 2>&1; then
                echo "Installing ansible"
                echo "${{ secrets.SUDO }}" | sudo -S apt-get update
                echo "${{ secrets.SUDO }}" | sudo -S apt-get install -y ansible
              fi
              echo "Running cert playbook for $FQDN"
              cd docker/certbot
              echo "localhost ansible_connection=local" > inventory.ini
              echo "${{ secrets.SUDO }}" | sudo -S ansible-playbook newcert.yml -i inventory.ini -e "domain_name=$FQDN email=${{ vars.EMAIL }} cloudflare_api_token=${{ secrets.CF_API_TOKEN }}"
              cd - >/dev/null
            fi

            # Allocate IP if needed
            IP_ADDRESS=""
            if [ "$DEDIP" = "true" ]; then
              echo "Allocating IP for $NAME on host $HOST"
              ENV_HOST="$HOST"
              if [ "$ENV_HOST" = "pi4" ]; then
                SUBNET="10.2.6"
              else
                SUBNET="10.2.5"
              fi
              HOST_PATH="$HOME/ipam"
              mkdir -p "$HOST_PATH"
              FILE="$HOST_PATH/ipam-${ENV_HOST}.csv"
              touch "$FILE"
              if ! grep -q '^ip,container' "$FILE"; then
                echo "ip,container" > tmp.csv
                grep -v '^ip,container' "$FILE" >> tmp.csv || true
                mv tmp.csv "$FILE"
              fi
              EXISTING_IP=$(awk -F',' -v c="$NAME" '$2==c {print $1}' "$FILE" | head -n1)
              if [ -n "$EXISTING_IP" ]; then
                IP_ADDRESS="$EXISTING_IP"
                echo "Found existing IP $IP_ADDRESS for $NAME"
              else
                for i in $(seq 2 254); do
                  IP="$SUBNET.$i"
                  if ! grep -q "$IP" "$FILE"; then
                    echo "$IP,$NAME" >> "$FILE"
                    IP_ADDRESS="$IP"
                    echo "Allocated $IP_ADDRESS to $NAME"
                    break
                  fi
                done
              fi
            fi

            # Create internal A record if needed
            if [ -n "$IP_ADDRESS" ]; then
              echo "Creating internal A record for $FQDN -> $IP_ADDRESS"
              cd infrastructure/dns/internal
              echo "localhost ansible_connection=local" > inventory.ini
              echo "${{ secrets.SUDO }}" | sudo -S ansible-playbook create_A_record.yml -i inventory.ini -e "technitium_api_token=${{ secrets.TECHITIUM_DNS_API_KEY }} allocated_ip=$IP_ADDRESS fqdn=$FQDN dns_server=${{ vars.DNS_SERVER }}"
              cd - >/dev/null
            fi

            # Deploy container
            echo "Deploying container $NAME from folder $FOLDER"
            BASE_DIR="docker/$FOLDER"
            cd "$BASE_DIR"
            echo "localhost ansible_connection=local" > inventory.ini
            printf '%s\n' "container_name: \"$NAME\"" "dedicated_ip: \"$IP_ADDRESS\"" "fqdn: \"$FQDN\"" "pfx_password: \"${{ secrets.PFX_PASSWORD }}\"" "container_password: \"${{ secrets.CONTAINER_PASSWORD }}\"" "googlemaps_api_key: \"${{ secrets.GOOGLEMAPS_API_KEY }}\"" > extra_vars.yml
            chmod 600 extra_vars.yml
            echo "${{ secrets.SUDO }}" | sudo -S ansible-playbook container_deploy.yml -i inventory.ini -e "@extra_vars.yml"
            shred -u extra_vars.yml || rm -f extra_vars.yml
            cd - >/dev/null

          done

  # downstream actions (cert creation, IP allocation, DNS record creation and deployment)
  # are handled sequentially inside the `read-config` job for each changed container.
      
